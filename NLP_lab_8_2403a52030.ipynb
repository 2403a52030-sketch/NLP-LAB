{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUEzV/8ceGHvNfqomFeiDR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52030-sketch/NLP-LAB/blob/main/NLP_lab_8_2403a52030.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfYpUpkb6pte",
        "outputId": "d340820a-419c-45f6-fb21-c1485c246ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Natural Language Toolkit for tokenization and n-grams\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# For text cleaning and mathematical operations\n",
        "import re\n",
        "import math\n",
        "\n",
        "# For counting word frequencies\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "# Download required NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c26efb04",
        "outputId": "9306a713-8c69-4ac5-9a21-88511cb28de2"
      },
      "source": [
        "# Load dataset from the correct path\n",
        "with open(\"/content/corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    corpus = f.read()\n",
        "\n",
        "# Display sample text\n",
        "print(corpus[:500])\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Natural language processing is a subfield of artificial intelligence that focuses on the interaction\n",
            "between computers and human language. It enables machines to read, understand, and generate text\n",
            "in a way that is meaningful. Over the years, natural language processing has evolved rapidly due to\n",
            "advances in machine learning and the availability of large datasets.\n",
            "\n",
            "Language models play a central role in natural language processing. A language model assigns\n",
            "probabilities to sequences of words an\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYK2xmCuBHzy",
        "outputId": "ced5a0e9-bd89-4b7d-ebbc-e487ff7431cb"
      },
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()                             # lowercase\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)            # remove punctuation & numbers\n",
        "    tokens = nltk.word_tokenize(text)               # tokenize\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [w for w in tokens if w not in stop_words]\n",
        "    return tokens\n",
        "\n",
        "tokens = preprocess_text(corpus)\n",
        "\n",
        "# Train-test split\n",
        "split = int(0.8 * len(tokens))\n",
        "train_tokens = tokens[:split]\n",
        "test_tokens = tokens[split:]\n",
        "\n",
        "print(\"Training tokens:\", len(train_tokens))\n",
        "print(\"Testing tokens:\", len(test_tokens))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training tokens: 392\n",
            "Testing tokens: 99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_ngram_model(tokens, n):\n",
        "    ngram_list = list(ngrams(tokens, n))\n",
        "    return Counter(ngram_list)\n",
        "\n",
        "unigram_counts = build_ngram_model(train_tokens, 1)\n",
        "bigram_counts = build_ngram_model(train_tokens, 2)\n",
        "trigram_counts = build_ngram_model(train_tokens, 3)\n",
        "\n",
        "print(\"Sample Unigrams:\", list(unigram_counts.items())[:5])\n",
        "print(\"Sample Bigrams:\", list(bigram_counts.items())[:5])\n",
        "print(\"Sample Trigrams:\", list(trigram_counts.items())[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9BUvOZdBjXm",
        "outputId": "0c773674-ce9f-4e14-a58e-88ffe9966323"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Unigrams: [(('natural',), 6), (('language',), 19), (('processing',), 5), (('subfield',), 1), (('artificial',), 1)]\n",
            "Sample Bigrams: [(('natural', 'language'), 5), (('language', 'processing'), 5), (('processing', 'subfield'), 1), (('subfield', 'artificial'), 1), (('artificial', 'intelligence'), 1)]\n",
            "Sample Trigrams: [(('natural', 'language', 'processing'), 5), (('language', 'processing', 'subfield'), 1), (('processing', 'subfield', 'artificial'), 1), (('subfield', 'artificial', 'intelligence'), 1), (('artificial', 'intelligence', 'focuses'), 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(set(train_tokens))\n",
        "\n",
        "def laplace_probability(ngram, ngram_counts, context_counts):\n",
        "    return (ngram_counts[ngram] + 1) / (context_counts + vocab_size)\n"
      ],
      "metadata": {
        "id": "I4WRohfBB0JR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_probability(sentence, n, ngram_counts, context_counts):\n",
        "    tokens = preprocess_text(sentence)\n",
        "    sentence_ngrams = list(ngrams(tokens, n))\n",
        "    prob = 1\n",
        "\n",
        "    for ng in sentence_ngrams:\n",
        "        prob *= laplace_probability(ng, ngram_counts, context_counts)\n",
        "\n",
        "    return prob\n",
        "\n",
        "sentences = [\n",
        "    \"natural language processing is interesting\",\n",
        "    \"language models predict words\",\n",
        "    \"this is a simple example\",\n",
        "    \"data science uses python\",\n",
        "    \"nltk is useful for nlp\"\n",
        "]\n",
        "\n",
        "for s in sentences:\n",
        "    print(\"\\nSentence:\", s)\n",
        "    print(\"Unigram Prob:\", sentence_probability(s, 1, unigram_counts, len(train_tokens)))\n",
        "    print(\"Bigram Prob:\", sentence_probability(s, 2, bigram_counts, len(train_tokens)))\n",
        "    print(\"Trigram Prob:\", sentence_probability(s, 3, trigram_counts, len(train_tokens)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5ewcNGMB3Kk",
        "outputId": "3862e342-bdeb-4d64-ada7-a5447fa543a4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: natural language processing is interesting\n",
            "Unigram Prob: 5.069867055196761e-09\n",
            "Bigram Prob: 1.386246506235229e-07\n",
            "Trigram Prob: 1.4740421182967935e-05\n",
            "\n",
            "Sentence: language models predict words\n",
            "Unigram Prob: 2.897066888683864e-08\n",
            "Bigram Prob: 3.0805477916338414e-08\n",
            "Trigram Prob: 2.456736863827989e-06\n",
            "\n",
            "Sentence: this is a simple example\n",
            "Unigram Prob: 4.913473727655978e-06\n",
            "Bigram Prob: 0.001567398119122257\n",
            "Trigram Prob: 1\n",
            "\n",
            "Sentence: data science uses python\n",
            "Unigram Prob: 4.828444814473106e-11\n",
            "Bigram Prob: 3.850684739542302e-09\n",
            "Trigram Prob: 2.456736863827989e-06\n",
            "\n",
            "Sentence: nltk is useful for nlp\n",
            "Unigram Prob: 3.850684739542302e-09\n",
            "Bigram Prob: 2.456736863827989e-06\n",
            "Trigram Prob: 0.001567398119122257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(sentence, n, ngram_counts, context_counts):\n",
        "    tokens = preprocess_text(sentence)\n",
        "    sentence_ngrams = list(ngrams(tokens, n))\n",
        "    log_prob = 0\n",
        "\n",
        "    if not sentence_ngrams: # Handle cases where no n-grams are formed\n",
        "        return float('inf') # Perplexity is undefined or infinite in this case\n",
        "\n",
        "    for ng in sentence_ngrams:\n",
        "        p = laplace_probability(ng, ngram_counts, context_counts)\n",
        "        log_prob += math.log(p)\n",
        "\n",
        "    return math.exp(-log_prob / len(sentence_ngrams))\n",
        "\n",
        "for s in sentences:\n",
        "    print(\"\\nSentence:\", s)\n",
        "    print(\"Unigram Perplexity:\", perplexity(s, 1, unigram_counts, len(train_tokens)))\n",
        "    print(\"Bigram Perplexity:\", perplexity(s, 2, bigram_counts, len(train_tokens)))\n",
        "    print(\"Trigram Perplexity:\", perplexity(s, 3, trigram_counts, len(train_tokens)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN_PwsagB6je",
        "outputId": "e7fbef7a-707d-40c0-8771-c23ad1c17dc2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence: natural language processing is interesting\n",
            "Unigram Perplexity: 118.50887003447242\n",
            "Bigram Perplexity: 193.22048970448424\n",
            "Trigram Perplexity: 260.4624093159446\n",
            "\n",
            "Sentence: language models predict words\n",
            "Unigram Perplexity: 76.64968411089865\n",
            "Bigram Perplexity: 318.99999999999994\n",
            "Trigram Perplexity: 637.9999999999999\n",
            "\n",
            "Sentence: this is a simple example\n",
            "Unigram Perplexity: 451.13412639701727\n",
            "Bigram Perplexity: 637.9999999999999\n",
            "Trigram Perplexity: inf\n",
            "\n",
            "Sentence: data science uses python\n",
            "Unigram Perplexity: 379.3570696858681\n",
            "Bigram Perplexity: 637.9999999999999\n",
            "Trigram Perplexity: 637.9999999999999\n",
            "\n",
            "Sentence: nltk is useful for nlp\n",
            "Unigram Perplexity: 637.9999999999999\n",
            "Bigram Perplexity: 637.9999999999999\n",
            "Trigram Perplexity: 637.9999999999999\n"
          ]
        }
      ]
    }
  ]
}